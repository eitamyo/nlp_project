{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18db031b",
   "metadata": {},
   "source": [
    "# Import Required Libraries\n",
    "Import torch and the necessary classes from the transformers library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08362824",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eitam\\miniconda3\\envs\\nikud-bert\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26e297a",
   "metadata": {},
   "source": [
    "# Load Tokenizer and Model\n",
    "Load the AutoTokenizer and AutoModel for 'dicta-il/dictabert-large-char-menaked'. Set the model to evaluation mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58436999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForDiacritization(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(1024, 1024, padding_idx=0)\n",
       "      (position_embeddings): Embedding(2048, 1024)\n",
       "      (token_type_embeddings): Embedding(2, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (menaked): BertMenakedHead(\n",
       "    (nikud_cls): Linear(in_features=1024, out_features=29, bias=True)\n",
       "    (shin_cls): Linear(in_features=1024, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"dicta-il/dictabert-large-char-menaked\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name, trust_remote_code=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a97c4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_probs(sentences, tokenizer, model, mark_matres_lectionis=None, top_k=5):\n",
    "    # Use model.predict for decoded output\n",
    "    decoded = model.predict(sentences, tokenizer, mark_matres_lectionis=mark_matres_lectionis)\n",
    "    \n",
    "    # Manual forward pass\n",
    "    inputs = tokenizer(sentences, padding='longest', truncation=True,\n",
    "                       return_tensors='pt', return_offsets_mapping=True)\n",
    "    offset_mapping = inputs.pop('offset_mapping')\n",
    "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.forward(**inputs, return_dict=True)\n",
    "    logits = outputs.logits  # MenakedLogitsOutput\n",
    "    nikud_logits = logits.nikud_logits  # [batch, seq_len, num_nikud]\n",
    "    shin_logits = logits.shin_logits    # [batch, seq_len, num_shin]\n",
    "    \n",
    "    results = []\n",
    "    for sent_idx, (sentence, offsets) in enumerate(zip(sentences, offset_mapping)):\n",
    "        # For each character token, collect top-k probabilities\n",
    "        sent_data = {'decoded': decoded[sent_idx], 'chars': []}\n",
    "        probs = torch.softmax(nikud_logits[sent_idx], dim=-1)  # probabilities\n",
    "        \n",
    "        for i, (start, end) in enumerate(offsets):\n",
    "            if end - start != 1:\n",
    "                continue\n",
    "            char = sentence[start:end]\n",
    "            dist = probs[i]\n",
    "            top_p, top_ids = torch.topk(dist, top_k)\n",
    "            sent_data['chars'].append({\n",
    "                'char': char,\n",
    "                'predictions': {\n",
    "                    model.config.nikud_classes[label_id.item()]: float(p.item())\n",
    "                    for p, label_id in zip(top_p, top_ids)\n",
    "                }\n",
    "            })\n",
    "        results.append(sent_data)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc071d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chars': [{'char': 'ל',\n",
      "            'predictions': {'ֵ': 0.30501502752304077,\n",
      "                            'ֶ': 0.4193100929260254,\n",
      "                            'ַ': 0.14278148114681244}},\n",
      "           {'char': 'י',\n",
      "            'predictions': {'': 0.6885529160499573,\n",
      "                            '<MAT_LECT>': 0.05325696989893913,\n",
      "                            'ְ': 0.15395373106002808}},\n",
      "           {'char': 'י',\n",
      "            'predictions': {'': 0.13126079738140106,\n",
      "                            '<MAT_LECT>': 0.8599182367324829,\n",
      "                            'ְ': 0.003723365720361471}},\n",
      "           {'char': 'ר',\n",
      "            'predictions': {'': 0.05877650901675224,\n",
      "                            'ֶ': 0.11981965601444244,\n",
      "                            'ָ': 0.8134917616844177}},\n",
      "           {'char': 'ה',\n",
      "            'predictions': {'': 0.9990084767341614,\n",
      "                            'ָ': 1.9796716514974833e-05,\n",
      "                            'ּ': 0.0008896052022464573}}],\n",
      " 'decoded': 'לֶירָה'}\n"
     ]
    }
   ],
   "source": [
    "res = predict_with_probs([\"ליירה\"], tokenizer, model, top_k=3)\n",
    "import pprint; pprint.pprint(res[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce2339f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log2\n",
    "\n",
    "def nikud_uncertainty(text, model, tokenizer, \n",
    "                      top_k=5, \n",
    "                      entropy_threshold=1.0, \n",
    "                      margin_threshold=0.2, \n",
    "                      maxprob_threshold=0.7):\n",
    "    \"\"\"\n",
    "    Identify ambiguous characters in the text according to nikud predictions.\n",
    "    \"\"\"\n",
    "    # Tokenize\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", return_offsets_mapping=True, truncation=True)\n",
    "    offsets = inputs.pop(\"offset_mapping\")[0]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)   # MenakedOutput\n",
    "        probs = torch.softmax(outputs.logits.nikud_logits[0], dim=-1)  # shape [seq_len, num_nikud_classes]\n",
    "\n",
    "    id2label = model.config.nikud_classes  # list of all nikud symbols\n",
    "\n",
    "    ambiguous = []\n",
    "    for i, (start, end) in enumerate(offsets):\n",
    "        if end - start != 1:  # skip special tokens / padding\n",
    "            continue\n",
    "        char = text[start:end]\n",
    "        dist = probs[i]\n",
    "\n",
    "        # Sort probabilities\n",
    "        sorted_probs, sorted_ids = torch.sort(dist, descending=True)\n",
    "        p1, p2 = sorted_probs[0].item(), sorted_probs[1].item()\n",
    "\n",
    "        # --- criteria ---\n",
    "        entropy = -sum(p.item() * log2(p.item()) for p in dist if p.item() > 0)\n",
    "        margin = p1 - p2\n",
    "        max_prob = p1\n",
    "\n",
    "        # decide ambiguity\n",
    "        is_ambig = (entropy > entropy_threshold) or (margin < margin_threshold) or (max_prob < maxprob_threshold)\n",
    "\n",
    "        if is_ambig:\n",
    "            ambiguous.append({\n",
    "                \"char\": char,\n",
    "                \"position\": (start, end),\n",
    "                \"entropy\": entropy,\n",
    "                \"margin\": margin,\n",
    "                \"max_prob\": max_prob,\n",
    "                \"top_candidates\": [\n",
    "                    (id2label[sorted_ids[j].item()], sorted_probs[j].item())\n",
    "                    for j in range(min(top_k, len(sorted_ids)))\n",
    "                ]\n",
    "            })\n",
    "    return ambiguous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df30e202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'char': ' ', 'position': (tensor(4), tensor(5)), 'entropy': 2.520866388614735, 'margin': 0.10133625566959381, 'max_prob': 0.3462553322315216, 'top_candidates': [('ָ', 0.3462553322315216), ('ֵ', 0.2449190765619278), ('', 0.2309339940547943), ('ִ', 0.0470949187874794), ('<MAT_LECT>', 0.0413050502538681)]}\n",
      "tensor(4)\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "ambig = nikud_uncertainty(\"שלום עולם\", model, tokenizer)\n",
    "for a in ambig:\n",
    "    print(a)\n",
    "    print(a[\"position\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041612dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a948ce20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.6-cp310-cp310-win_amd64.whl.metadata (11 kB)\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.2-cp310-cp310-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.59.2-cp310-cp310-win_amd64.whl.metadata (111 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.9-cp310-cp310-win_amd64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\eitam\\miniconda3\\envs\\nikud-bert\\lib\\site-packages (from matplotlib) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\eitam\\miniconda3\\envs\\nikud-bert\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-11.3.0-cp310-cp310-win_amd64.whl.metadata (9.2 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\eitam\\miniconda3\\envs\\nikud-bert\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\eitam\\miniconda3\\envs\\nikud-bert\\lib\\site-packages (from seaborn) (2.3.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\eitam\\miniconda3\\envs\\nikud-bert\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\eitam\\miniconda3\\envs\\nikud-bert\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\eitam\\miniconda3\\envs\\nikud-bert\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Downloading matplotlib-3.10.6-cp310-cp310-win_amd64.whl (8.1 MB)\n",
      "   ---------------------------------------- 0.0/8.1 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 1.0/8.1 MB 7.2 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 3.1/8.1 MB 9.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 5.8/8.1 MB 10.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 7.9/8.1 MB 10.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.1/8.1 MB 9.7 MB/s eta 0:00:00\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Downloading contourpy-1.3.2-cp310-cp310-win_amd64.whl (221 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.59.2-cp310-cp310-win_amd64.whl (2.3 MB)\n",
      "   ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "   ------------------------------------- -- 2.1/2.3 MB 11.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.3/2.3 MB 9.1 MB/s eta 0:00:00\n",
      "Downloading kiwisolver-1.4.9-cp310-cp310-win_amd64.whl (73 kB)\n",
      "Downloading pillow-11.3.0-cp310-cp310-win_amd64.whl (7.0 MB)\n",
      "   ---------------------------------------- 0.0/7.0 MB ? eta -:--:--\n",
      "   --------------- ------------------------ 2.6/7.0 MB 11.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 5.0/7.0 MB 11.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.8/7.0 MB 11.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.0/7.0 MB 10.2 MB/s eta 0:00:00\n",
      "Downloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib, seaborn\n",
      "\n",
      "   ---------------------------------------- 0/8 [pyparsing]\n",
      "   ----- ---------------------------------- 1/8 [pillow]\n",
      "   ----- ---------------------------------- 1/8 [pillow]\n",
      "   ----- ---------------------------------- 1/8 [pillow]\n",
      "   ----- ---------------------------------- 1/8 [pillow]\n",
      "   ----- ---------------------------------- 1/8 [pillow]\n",
      "   ----- ---------------------------------- 1/8 [pillow]\n",
      "   ----- ---------------------------------- 1/8 [pillow]\n",
      "   ----- ---------------------------------- 1/8 [pillow]\n",
      "   ----- ---------------------------------- 1/8 [pillow]\n",
      "   ----- ---------------------------------- 1/8 [pillow]\n",
      "   ----- ---------------------------------- 1/8 [pillow]\n",
      "   ----- ---------------------------------- 1/8 [pillow]\n",
      "   ----- ---------------------------------- 1/8 [pillow]\n",
      "   ----- ---------------------------------- 1/8 [pillow]\n",
      "   ----- ---------------------------------- 1/8 [pillow]\n",
      "   ----- ---------------------------------- 1/8 [pillow]\n",
      "   ----- ---------------------------------- 1/8 [pillow]\n",
      "   ---------- ----------------------------- 2/8 [kiwisolver]\n",
      "   --------------- ------------------------ 3/8 [fonttools]\n",
      "   --------------- ------------------------ 3/8 [fonttools]\n",
      "   --------------- ------------------------ 3/8 [fonttools]\n",
      "   --------------- ------------------------ 3/8 [fonttools]\n",
      "   --------------- ------------------------ 3/8 [fonttools]\n",
      "   --------------- ------------------------ 3/8 [fonttools]\n",
      "   --------------- ------------------------ 3/8 [fonttools]\n",
      "   --------------- ------------------------ 3/8 [fonttools]\n",
      "   --------------- ------------------------ 3/8 [fonttools]\n",
      "   --------------- ------------------------ 3/8 [fonttools]\n",
      "   --------------- ------------------------ 3/8 [fonttools]\n",
      "   --------------- ------------------------ 3/8 [fonttools]\n",
      "   --------------- ------------------------ 3/8 [fonttools]\n",
      "   --------------- ------------------------ 3/8 [fonttools]\n",
      "   --------------- ------------------------ 3/8 [fonttools]\n",
      "   --------------- ------------------------ 3/8 [fonttools]\n",
      "   --------------- ------------------------ 3/8 [fonttools]\n",
      "   --------------- ------------------------ 3/8 [fonttools]\n",
      "   --------------- ------------------------ 3/8 [fonttools]\n",
      "   --------------- ------------------------ 3/8 [fonttools]\n",
      "   --------------- ------------------------ 3/8 [fonttools]\n",
      "   --------------- ------------------------ 3/8 [fonttools]\n",
      "   --------------- ------------------------ 3/8 [fonttools]\n",
      "   --------------- ------------------------ 3/8 [fonttools]\n",
      "   --------------- ------------------------ 3/8 [fonttools]\n",
      "   --------------- ------------------------ 3/8 [fonttools]\n",
      "   --------------- ------------------------ 3/8 [fonttools]\n",
      "   --------------- ------------------------ 3/8 [fonttools]\n",
      "   --------------- ------------------------ 3/8 [fonttools]\n",
      "   --------------- ------------------------ 3/8 [fonttools]\n",
      "   --------------- ------------------------ 3/8 [fonttools]\n",
      "   --------------- ------------------------ 3/8 [fonttools]\n",
      "   --------------- ------------------------ 3/8 [fonttools]\n",
      "   --------------- ------------------------ 3/8 [fonttools]\n",
      "   --------------- ------------------------ 3/8 [fonttools]\n",
      "   --------------- ------------------------ 3/8 [fonttools]\n",
      "   --------------- ------------------------ 3/8 [fonttools]\n",
      "   --------------- ------------------------ 3/8 [fonttools]\n",
      "   --------------- ------------------------ 3/8 [fonttools]\n",
      "   --------------- ------------------------ 3/8 [fonttools]\n",
      "   --------------- ------------------------ 3/8 [fonttools]\n",
      "   --------------- ------------------------ 3/8 [fonttools]\n",
      "   --------------- ------------------------ 3/8 [fonttools]\n",
      "   --------------- ------------------------ 3/8 [fonttools]\n",
      "   --------------- ------------------------ 3/8 [fonttools]\n",
      "   --------------- ------------------------ 3/8 [fonttools]\n",
      "   --------------- ------------------------ 3/8 [fonttools]\n",
      "   --------------- ------------------------ 3/8 [fonttools]\n",
      "   --------------- ------------------------ 3/8 [fonttools]\n",
      "   --------------- ------------------------ 3/8 [fonttools]\n",
      "   --------------- ------------------------ 3/8 [fonttools]\n",
      "   --------------- ------------------------ 3/8 [fonttools]\n",
      "   --------------- ------------------------ 3/8 [fonttools]\n",
      "   --------------- ------------------------ 3/8 [fonttools]\n",
      "   --------------- ------------------------ 3/8 [fonttools]\n",
      "   ------------------------- -------------- 5/8 [contourpy]\n",
      "   ------------------------- -------------- 5/8 [contourpy]\n",
      "   ------------------------- -------------- 5/8 [contourpy]\n",
      "   ------------------------------ --------- 6/8 [matplotlib]\n",
      "   ------------------------------ --------- 6/8 [matplotlib]\n",
      "   ------------------------------ --------- 6/8 [matplotlib]\n",
      "   ------------------------------ --------- 6/8 [matplotlib]\n",
      "   ------------------------------ --------- 6/8 [matplotlib]\n",
      "   ------------------------------ --------- 6/8 [matplotlib]\n",
      "   ------------------------------ --------- 6/8 [matplotlib]\n",
      "   ------------------------------ --------- 6/8 [matplotlib]\n",
      "   ------------------------------ --------- 6/8 [matplotlib]\n",
      "   ------------------------------ --------- 6/8 [matplotlib]\n",
      "   ------------------------------ --------- 6/8 [matplotlib]\n",
      "   ------------------------------ --------- 6/8 [matplotlib]\n",
      "   ------------------------------ --------- 6/8 [matplotlib]\n",
      "   ------------------------------ --------- 6/8 [matplotlib]\n",
      "   ------------------------------ --------- 6/8 [matplotlib]\n",
      "   ------------------------------ --------- 6/8 [matplotlib]\n",
      "   ------------------------------ --------- 6/8 [matplotlib]\n",
      "   ------------------------------ --------- 6/8 [matplotlib]\n",
      "   ------------------------------ --------- 6/8 [matplotlib]\n",
      "   ------------------------------ --------- 6/8 [matplotlib]\n",
      "   ------------------------------ --------- 6/8 [matplotlib]\n",
      "   ------------------------------ --------- 6/8 [matplotlib]\n",
      "   ------------------------------ --------- 6/8 [matplotlib]\n",
      "   ------------------------------ --------- 6/8 [matplotlib]\n",
      "   ------------------------------ --------- 6/8 [matplotlib]\n",
      "   ------------------------------ --------- 6/8 [matplotlib]\n",
      "   ------------------------------ --------- 6/8 [matplotlib]\n",
      "   ------------------------------ --------- 6/8 [matplotlib]\n",
      "   ------------------------------ --------- 6/8 [matplotlib]\n",
      "   ------------------------------ --------- 6/8 [matplotlib]\n",
      "   ------------------------------ --------- 6/8 [matplotlib]\n",
      "   ------------------------------ --------- 6/8 [matplotlib]\n",
      "   ------------------------------ --------- 6/8 [matplotlib]\n",
      "   ------------------------------ --------- 6/8 [matplotlib]\n",
      "   ------------------------------ --------- 6/8 [matplotlib]\n",
      "   ------------------------------ --------- 6/8 [matplotlib]\n",
      "   ------------------------------ --------- 6/8 [matplotlib]\n",
      "   ------------------------------ --------- 6/8 [matplotlib]\n",
      "   ------------------------------ --------- 6/8 [matplotlib]\n",
      "   ------------------------------ --------- 6/8 [matplotlib]\n",
      "   ------------------------------ --------- 6/8 [matplotlib]\n",
      "   ------------------------------ --------- 6/8 [matplotlib]\n",
      "   ------------------------------ --------- 6/8 [matplotlib]\n",
      "   ------------------------------ --------- 6/8 [matplotlib]\n",
      "   ------------------------------ --------- 6/8 [matplotlib]\n",
      "   ------------------------------ --------- 6/8 [matplotlib]\n",
      "   ------------------------------ --------- 6/8 [matplotlib]\n",
      "   ------------------------------ --------- 6/8 [matplotlib]\n",
      "   ------------------------------ --------- 6/8 [matplotlib]\n",
      "   ------------------------------ --------- 6/8 [matplotlib]\n",
      "   ------------------------------ --------- 6/8 [matplotlib]\n",
      "   ------------------------------ --------- 6/8 [matplotlib]\n",
      "   ------------------------------ --------- 6/8 [matplotlib]\n",
      "   ------------------------------ --------- 6/8 [matplotlib]\n",
      "   ------------------------------ --------- 6/8 [matplotlib]\n",
      "   ------------------------------ --------- 6/8 [matplotlib]\n",
      "   ------------------------------ --------- 6/8 [matplotlib]\n",
      "   ------------------------------ --------- 6/8 [matplotlib]\n",
      "   ------------------------------ --------- 6/8 [matplotlib]\n",
      "   ------------------------------ --------- 6/8 [matplotlib]\n",
      "   ------------------------------ --------- 6/8 [matplotlib]\n",
      "   ------------------------------ --------- 6/8 [matplotlib]\n",
      "   ------------------------------ --------- 6/8 [matplotlib]\n",
      "   ----------------------------------- ---- 7/8 [seaborn]\n",
      "   ----------------------------------- ---- 7/8 [seaborn]\n",
      "   ----------------------------------- ---- 7/8 [seaborn]\n",
      "   ----------------------------------- ---- 7/8 [seaborn]\n",
      "   ----------------------------------- ---- 7/8 [seaborn]\n",
      "   ----------------------------------- ---- 7/8 [seaborn]\n",
      "   ----------------------------------- ---- 7/8 [seaborn]\n",
      "   ----------------------------------- ---- 7/8 [seaborn]\n",
      "   ----------------------------------- ---- 7/8 [seaborn]\n",
      "   ---------------------------------------- 8/8 [seaborn]\n",
      "\n",
      "Successfully installed contourpy-1.3.2 cycler-0.12.1 fonttools-4.59.2 kiwisolver-1.4.9 matplotlib-3.10.6 pillow-11.3.0 pyparsing-3.2.3 seaborn-0.13.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "192c7624",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eitam\\AppData\\Local\\Temp\\ipykernel_15992\\20511882.py:49: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  cmap = matplotlib.cm.get_cmap(\"YlOrRd\")  # bright yellow → orange → red\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style='color:#ffffcc'>א</span><span style='color:#ffffcc'>ל</span><span style='color:#ffffcc'>ו</span><span style='color:#ffffcc'>ן</span><span style='color:#ffe794'> </span><span style='color:#ffffcc'>ה</span><span style='color:#ffffcc'>א</span><span style='color:#ffffcc'>ח</span><span style='color:#ffe793'> </span><span style='color:#ffffcc'>ח</span><span style='color:#ffffcc'>ב</span><span style='color:#ffffcc'>ר</span><span style='color:#ffe58f'> </span><span style='color:#ffffcc'>ט</span><span style='color:#ffffcc'>ו</span><span style='color:#ffffcc'>ב</span><span style='color:#ffe998'> </span><span style='color:#ffffcc'>ש</span><span style='color:#ffffcc'>ל</span><span style='color:#ffe895'> </span><span style='color:#800026'>כ</span><span style='color:#800026'>ד</span><span style='color:#fedb7a'>ר</span><span style='color:#fead4a'>ל</span><span style='color:#fed06c'>ע</span><span style='color:#800026'>ו</span><span style='color:#fc6430'>מ</span><span style='color:#ffffcc'>ר</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import HTML, display\n",
    "import matplotlib\n",
    "import math\n",
    "\n",
    "def colorize_text_by_certainty(text, model, tokenizer,\n",
    "                               certainty_metric=\"max_prob\",\n",
    "                               scale=\"linear\",\n",
    "                               low_conf=0.6, high_conf=0.95):\n",
    "    \"\"\"\n",
    "    Display text with characters color-coded by certainty.\n",
    "    Uses a bright palette (yellow → orange → red) for better contrast on dark backgrounds.\n",
    "    \"\"\"\n",
    "    # Tokenize\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", return_offsets_mapping=True, truncation=True)\n",
    "    offsets = inputs.pop(\"offset_mapping\")[0]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        nikud_probs = torch.softmax(outputs.logits.nikud_logits[0], dim=-1)\n",
    "\n",
    "    html_chars = []\n",
    "\n",
    "    for i, (start, end) in enumerate(offsets):\n",
    "        if end - start != 1:\n",
    "            continue\n",
    "        char = text[start:end]\n",
    "        dist = nikud_probs[i]\n",
    "\n",
    "        # Certainty metric\n",
    "        if certainty_metric == \"max_prob\":\n",
    "            conf = dist.max().item()\n",
    "        elif certainty_metric == \"entropy\":\n",
    "            entropy = -sum(p.item() * math.log2(p.item()) for p in dist if p.item() > 0)\n",
    "            conf = 1 - entropy / math.log2(len(dist))\n",
    "        else:\n",
    "            raise ValueError(\"Unknown certainty metric\")\n",
    "\n",
    "        # Normalize to [0,1]\n",
    "        norm = (conf - low_conf) / (high_conf - low_conf)\n",
    "        norm = min(max(norm, 0.0), 1.0)\n",
    "\n",
    "        # Apply scaling\n",
    "        if scale == \"sqrt\":\n",
    "            norm = norm**0.5\n",
    "        elif scale == \"log\":\n",
    "            norm = (math.log1p(norm * 9) / math.log1p(9)) if norm > 0 else 0\n",
    "\n",
    "        # Bright colormap (avoid dark colors)\n",
    "        cmap = matplotlib.cm.get_cmap(\"YlOrRd\")  # bright yellow → orange → red\n",
    "        rgba = cmap(1 - norm)  # invert: high conf → yellow, low conf → red\n",
    "        color = matplotlib.colors.rgb2hex(rgba)\n",
    "\n",
    "        html_chars.append(f\"<span style='color:{color}'>{char}</span>\")\n",
    "\n",
    "    display(HTML(\"\".join(html_chars)))\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "colorize_text_by_certainty(\"אלון האח חבר טוב של כדרלעומר\", model, tokenizer,\n",
    "                           certainty_metric=\"max_prob\",\n",
    "                           scale=\"sqrt\", low_conf=0.6, high_conf=0.95)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nikud-bert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
