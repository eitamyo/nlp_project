{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ad22061e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/hewiki/hebrew_nikud_dataset_filtered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "08a2b81a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import utils.hebrew_tokenizer as ht\n",
    "\n",
    "ht.get_nikud_uncertainty(df.iloc[0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "69a4f965",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def mask_str(mask):\n",
    "    if isinstance(mask, str):\n",
    "        mask = ast.literal_eval(mask)\n",
    "    return \"\".join([str(x) for x in mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d007d6ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a8267820cec448888b0de3d96d8e7a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checking mask lengths:   0%|          | 0/81995 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(788, 6)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "mask_lengths = []\n",
    "for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Checking mask lengths\"):\n",
    "    mask_lengths.append(len(ht.get_nikud_mask(row['text'])[1]))\n",
    "\n",
    "mismatch_rows = df[[mask_len != row['nikud_mask_length'] for mask_len, (_, row) in zip(mask_lengths, df.iterrows())]]\n",
    "mismatch_rows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "87ecf682",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eitam\\AppData\\Local\\Temp\\ipykernel_13756\\2918813076.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mismatch_rows['diff'] = [len(ht.get_nikud_mask(row['text'])[1]) - row['nikud_mask_length'] for _, row in mismatch_rows.iterrows()]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "diff\n",
       "-3      1\n",
       "-2     59\n",
       "-1    728\n",
       "dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mismatch_rows['diff'] = [len(ht.get_nikud_mask(row['text'])[1]) - row['nikud_mask_length'] for _, row in mismatch_rows.iterrows()]\n",
    "grouped = mismatch_rows.groupby('diff')\n",
    "grouped.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8881d602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "גַ'לְג'וּלְיָה (בערבית: جلجولية) היא מועצה מקומית ערבית-מוסלמית במחוז המרכז בישראל, 3 ק\"מ מזרחית לכפר סבא\n",
      "[CLS] ג'ל ג'ו ל י ה   ( ב ע ר ב י ת :   [UNK] )   ה י א   מ ו ע צ ה   מ ק ו מ י ת   ע ר ב י ת - מ ו ס ל מ י ת   ב מ ח ו ז   ה מ ר כ ז   ב י ש ר א ל,   3   ק \" מ   מ ז ר ח י ת   ל כ פ ר   ס ב א [SEP]\n",
      "010100111000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n",
      "0010100111000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n"
     ]
    }
   ],
   "source": [
    "x = grouped.get_group(-1).iloc[10]\n",
    "print(x['text'])\n",
    "input_ids, nikud_mask = ht.get_nikud_mask(x['text'])\n",
    "print(ht.tokenizer.decode(input_ids))\n",
    "print(mask_str(nikud_mask))\n",
    "print(mask_str(x['nikud_mask']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "011aec8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text                 המכללה מפוזרת במספר מבנים במרכז לונדון כאשר הב...\n",
       "nikud_mask           [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "article_title                                בירקבק, אוניברסיטת לונדון\n",
       "article_length                                                    1508\n",
       "text_length                                                        215\n",
       "nikud_mask_length                                                  216\n",
       "Name: 36795, dtype: object"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = df.sample(1)\n",
    "sample.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a14f1f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] ה מ כ ל ל ה   מ פ ו ז ר ת   ב מ ס פ ר   מ ב נ י ם   ב מ ר כ ז   ל ו נ ד ו ן   כ א ש ר   ה ב נ י י ן   ה ר א ש י,   ש ה י ה   י ד ו ע   ב ש ם   \" ה מ כ ו ן   ה מ ד ע י   ו ה ס פ ר ו ת י   ע ל   ש ם   ב י ר ק ב ק \",   ש ו כ ן   ב י ן   ר ח ו ב   מ א ל ט   ( m a l e t )   ו כ י כ ר   ו ו ב ו ר ן   ( w o b u r n   s q u a r e )   ב ב ל ו מ ס ב ר י,   ו ב נ י י נ י ם   נ ו ס פ י ם   ש ו כ נ י ם   ב ר ח ו ב ו ת   ה ס מ ו כ י ם [SEP] 216 216\n"
     ]
    }
   ],
   "source": [
    "input_ids, nikud_mask = ht.get_nikud_mask(sample.iloc[0]['text'])\n",
    "print(ht.tokenizer.decode(input_ids), len(mask_str(nikud_mask)), len(mask_str(sample.iloc[0]['nikud_mask'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fd19b5d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('המכללה מפוזרת במספר מבנים במרכז לונדון כאשר הבניין הראשי, שהיה ידוע בשם \"המכון המדעי והספרותי על שם בירקבק\", שוכן בין רחוב מאלֶט (Malet) וכיכר וובורן (Woburn Square) בבלומסברי, ובניינים נוספים שוכנים ברחובות הסמוכים',\n",
       " '000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000100000000000000000000000000000000000000000000000000000000000000000000000000000000000000000',\n",
       " '000000000000000000000000000000000000000000000000000000000000000000000100000000000000000000000000000000011100000000000000000000100000000000000001111100000000000000000010011010000000000000000000000000000000000000000000',\n",
       " [{'char': 'ב',\n",
       "   'position': (tensor(68), tensor(69)),\n",
       "   'entropy': 0.9616581188229713,\n",
       "   'margin': 0.3270113468170166,\n",
       "   'max_prob': 0.6616202592849731,\n",
       "   'top_candidates': [('ַּ', 0.6616202592849731),\n",
       "    ('ְּ', 0.33460891246795654),\n",
       "    ('ִּ', 0.002159330528229475),\n",
       "    ('ָּ', 0.0005361863877624273),\n",
       "    ('ֶּ', 0.00037697318475693464)]},\n",
       "  {'char': 'ר',\n",
       "   'position': (tensor(102), tensor(103)),\n",
       "   'entropy': 1.8711818040541932,\n",
       "   'margin': 0.38385285437107086,\n",
       "   'max_prob': 0.5777952075004578,\n",
       "   'top_candidates': [('ְ', 0.5777952075004578),\n",
       "    ('', 0.1939423531293869),\n",
       "    ('ֶ', 0.11990911513566971),\n",
       "    ('ַ', 0.04931758716702461),\n",
       "    ('ֵ', 0.02293713204562664)]},\n",
       "  {'char': 'ק',\n",
       "   'position': (tensor(103), tensor(104)),\n",
       "   'entropy': 2.7263243031817694,\n",
       "   'margin': 0.01284065842628479,\n",
       "   'max_prob': 0.21474286913871765,\n",
       "   'top_candidates': [('ְ', 0.21474286913871765),\n",
       "    ('', 0.20190221071243286),\n",
       "    ('ַ', 0.18625548481941223),\n",
       "    ('ֶ', 0.1438208818435669),\n",
       "    ('ֵ', 0.14312273263931274)]},\n",
       "  {'char': 'ב',\n",
       "   'position': (tensor(104), tensor(105)),\n",
       "   'entropy': 2.2002625618508365,\n",
       "   'margin': 0.3226827085018158,\n",
       "   'max_prob': 0.520965039730072,\n",
       "   'top_candidates': [('ֵּ', 0.520965039730072),\n",
       "    ('ֶּ', 0.19828233122825623),\n",
       "    ('ֶ', 0.12296167761087418),\n",
       "    ('', 0.03919311612844467),\n",
       "    ('ֵ', 0.03551114723086357)]},\n",
       "  {'char': 'ל',\n",
       "   'position': (tensor(125), tensor(126)),\n",
       "   'entropy': 1.8963444172466186,\n",
       "   'margin': 0.10068380832672119,\n",
       "   'max_prob': 0.4467373192310333,\n",
       "   'top_candidates': [('ְ', 0.4467373192310333),\n",
       "    ('ֶ', 0.34605351090431213),\n",
       "    ('', 0.13237985968589783),\n",
       "    ('ָ', 0.031192421913146973),\n",
       "    ('ֵ', 0.022757135331630707)]},\n",
       "  {'char': 'ו',\n",
       "   'position': (tensor(143), tensor(144)),\n",
       "   'entropy': 1.5009125273616222,\n",
       "   'margin': 0.6502422541379929,\n",
       "   'max_prob': 0.7513085007667542,\n",
       "   'top_candidates': [('', 0.7513085007667542),\n",
       "    ('ֶ', 0.10106624662876129),\n",
       "    ('ּ', 0.028528427705168724),\n",
       "    ('ֹ', 0.025048380717635155),\n",
       "    ('<MAT_LECT>', 0.02298285812139511)]},\n",
       "  {'char': 'ו',\n",
       "   'position': (tensor(144), tensor(145)),\n",
       "   'entropy': 1.910976630550734,\n",
       "   'margin': 0.12372845411300659,\n",
       "   'max_prob': 0.42514467239379883,\n",
       "   'top_candidates': [('ֹ', 0.42514467239379883),\n",
       "    ('', 0.30141621828079224),\n",
       "    ('ּ', 0.15977902710437775),\n",
       "    ('<MAT_LECT>', 0.10325903445482254),\n",
       "    ('ְ', 0.003226060187444091)]},\n",
       "  {'char': 'ב',\n",
       "   'position': (tensor(145), tensor(146)),\n",
       "   'entropy': 1.0326104128679015,\n",
       "   'margin': 0.1594308316707611,\n",
       "   'max_prob': 0.5776330828666687,\n",
       "   'top_candidates': [('', 0.5776330828666687),\n",
       "    ('ּ', 0.4182022511959076),\n",
       "    ('ֹּ', 0.0005819361540488899),\n",
       "    ('ְ', 0.0004870575503446162),\n",
       "    ('ֹ', 0.00046099082101136446)]},\n",
       "  {'char': 'ו',\n",
       "   'position': (tensor(146), tensor(147)),\n",
       "   'entropy': 1.2335868653931932,\n",
       "   'margin': 0.5488305687904358,\n",
       "   'max_prob': 0.713856041431427,\n",
       "   'top_candidates': [('ֹ', 0.713856041431427),\n",
       "    ('ּ', 0.1650254726409912),\n",
       "    ('', 0.107624851167202),\n",
       "    ('<MAT_LECT>', 0.009259399026632309),\n",
       "    ('ֵ', 0.001007733284495771)]},\n",
       "  {'char': 'ר',\n",
       "   'position': (tensor(147), tensor(148)),\n",
       "   'entropy': 1.09150466846497,\n",
       "   'margin': 0.7406834736466408,\n",
       "   'max_prob': 0.8088375329971313,\n",
       "   'top_candidates': [('ְ', 0.8088375329971313),\n",
       "    ('ֶ', 0.06815405935049057),\n",
       "    ('', 0.06601420044898987),\n",
       "    ('ָ', 0.031088147312402725),\n",
       "    ('ֵ', 0.021379953250288963)]},\n",
       "  {'char': 'ב',\n",
       "   'position': (tensor(166), tensor(167)),\n",
       "   'entropy': 1.173153969120339,\n",
       "   'margin': 0.42317068576812744,\n",
       "   'max_prob': 0.6882004737854004,\n",
       "   'top_candidates': [('ִּ', 0.6882004737854004),\n",
       "    ('ְּ', 0.26502978801727295),\n",
       "    ('', 0.02549128606915474),\n",
       "    ('ַּ', 0.014537468552589417),\n",
       "    ('ִ', 0.0015429664636030793)]},\n",
       "  {'char': 'ו',\n",
       "   'position': (tensor(169), tensor(170)),\n",
       "   'entropy': 1.3341644141452975,\n",
       "   'margin': 0.1149369478225708,\n",
       "   'max_prob': 0.5221803784370422,\n",
       "   'top_candidates': [('ֹ', 0.5221803784370422),\n",
       "    ('ּ', 0.40724343061447144),\n",
       "    ('', 0.06467641890048981),\n",
       "    ('<MAT_LECT>', 0.0029579538386315107),\n",
       "    ('ֵ', 0.0003483237815089524)]},\n",
       "  {'char': 'מ',\n",
       "   'position': (tensor(170), tensor(171)),\n",
       "   'entropy': 1.063686037475165,\n",
       "   'margin': 0.7164718508720398,\n",
       "   'max_prob': 0.8029094338417053,\n",
       "   'top_candidates': [('ְ', 0.8029094338417053),\n",
       "    ('ֶ', 0.08643758296966553),\n",
       "    ('', 0.08472495526075363),\n",
       "    ('ַ', 0.01072676107287407),\n",
       "    ('ָ', 0.00633619911968708)]},\n",
       "  {'char': 'ב',\n",
       "   'position': (tensor(172), tensor(173)),\n",
       "   'entropy': 2.2408375476062834,\n",
       "   'margin': 0.18732950091362,\n",
       "   'max_prob': 0.43791669607162476,\n",
       "   'top_candidates': [('ֵּ', 0.43791669607162476),\n",
       "    ('ְּ', 0.25058719515800476),\n",
       "    ('ָּ', 0.13168728351593018),\n",
       "    ('', 0.08287357538938522),\n",
       "    ('ְ', 0.05060029402375221)]}])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "uncertainty_mask, ambiguous_chars = ht.get_nikud_uncertainty(sample.iloc[0]['text'])\n",
    "sample.iloc[0]['text'], mask_str(sample.iloc[0]['nikud_mask']), mask_str(uncertainty_mask), ambiguous_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "792e78dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df = df.sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a217bc4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c996932257434904b73ef9de0c9d74a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating uncertainty masks:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "tqdm.pandas(desc=\"Calculating uncertainty masks\")\n",
    "small_df['uncertainty_mask'] = small_df['text'].progress_apply(lambda text: ht.get_nikud_uncertainty(text)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "bb9053a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_token_to_word_mask(text: str, mask):\n",
    "    \"\"\"\n",
    "    Convert a token-level mask to a word-level mask.\n",
    "    A word is considered to have nikud if any of its tokens have nikud.\n",
    "    \"\"\"\n",
    "    tokens = ht.tokenizer.tokenize(text)\n",
    "    # print(tokens)\n",
    "    if isinstance(mask, str):\n",
    "        mask = ast.literal_eval(mask)\n",
    "    # assert len(tokens) == len(mask), f\"Token and mask lengths do not match: {len(tokens)} != {len(mask)}\"\n",
    "    word_mask = []\n",
    "    current_word_has_nikud = False\n",
    "    is_in_word = False\n",
    "\n",
    "    for token, m in zip(tokens, mask):\n",
    "        if token == ' ':  # space token\n",
    "            if is_in_word:  # end of a word\n",
    "                if current_word_has_nikud:\n",
    "                    word_mask.append(1)\n",
    "                else:\n",
    "                    word_mask.append(0)\n",
    "                is_in_word = False\n",
    "                current_word_has_nikud = False\n",
    "        else:  # part of a word\n",
    "            is_in_word = True\n",
    "            if m == 1:\n",
    "                current_word_has_nikud = True\n",
    "\n",
    "    # Append mask for the last word\n",
    "    if is_in_word:\n",
    "        if current_word_has_nikud:\n",
    "            word_mask.append(1)\n",
    "        else:\n",
    "            word_mask.append(0)\n",
    "\n",
    "    return word_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7e98a30f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b2d5449da784ce698033deecac1599f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating uncertainty masks:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2db840a5fe934388b141ea94b6f50ffb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating uncertainty masks:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "small_df['nikud_word_mask'] = small_df.progress_apply(\n",
    "    lambda row: convert_token_to_word_mask(row['text'], row['nikud_mask']), axis=1)\n",
    "small_df['uncertainty_word_mask'] = small_df.progress_apply(\n",
    "    lambda row: convert_token_to_word_mask(row['text'], row['uncertainty_mask']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1d9024bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 26)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(small_df.iloc[0]['uncertainty_word_mask']), len(small_df.iloc[0]['nikud_word_mask'])\n",
    "# convert_token_to_word_mask(small_df.iloc[0]['text'], small_df.iloc[0]['uncertainty_mask'])\n",
    "# convert_token_to_word_mask(small_df.iloc[0]['text'], small_df.iloc[0]['uncertainty_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3960e0ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    957.000000\n",
       "mean       0.620606\n",
       "std        0.445497\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        1.000000\n",
       "75%        1.000000\n",
       "max        1.000000\n",
       "Name: uncertainty_overlap_ratio, dtype: float64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Compute the overlap ratio in a separate step\n",
    "def overlap_ratio(row):\n",
    "    uncertainty_mask = row['uncertainty_word_mask']\n",
    "    nikud_mask = row['nikud_word_mask']\n",
    "    if isinstance(nikud_mask, str):\n",
    "        nikud_mask = ast.literal_eval(nikud_mask)\n",
    "    overlap = sum(1 for u, n in zip(uncertainty_mask, nikud_mask) if u == 1 and n == 1)\n",
    "    total_nikud = sum(nikud_mask)\n",
    "    return overlap / total_nikud if total_nikud > 0 else None\n",
    "\n",
    "small_df['uncertainty_overlap_ratio'] = small_df.apply(overlap_ratio, axis=1)\n",
    "small_df['uncertainty_overlap_ratio'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "247c4b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_enough_overlap = small_df[small_df['uncertainty_overlap_ratio'] <= 0.5]\n",
    "test = not_enough_overlap.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8e250988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1:\n",
      "Text: הפילוסוף ג'ון סטיוארט מיל בספרו הידוע \"מערכת לוגית\" (A System of Logic) הרבה להתווכח עם יוּאֶל, אך הודה בהקדמה לספר כי הושפע מהידע והרעיונות שקרא בספר \"היסטוריה של המדעים האינדוקטיביים\" של יוּאֶל\n",
      "Nikud Mask:       0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001100000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001100\n",
      "Uncertainty Mask: 0000000000000000001000000000000000000000000000000000000000000000000000000100000000000000000000000000000100000000000000000000000000000000000000000000000000000000000000000000000100000000000000000\n",
      "Overlap Ratio: 0.0\n",
      "\n",
      "Example 2:\n",
      "Text: ארץ שיש בה השגחה אלוהית מיוחדת ותמידית: \"אֶרֶץ אֲשֶׁר ה' אֱלֹהֶיךָ דֹּרֵשׁ אֹתָהּ, תָּמִיד עֵינֵי ה' אֱלֹהֶיךָ בָּהּ, מֵרֵשִׁית הַשָּׁנָה וְעַד אַחֲרִית שָׁנָה:\" ()\n",
      "Nikud Mask:       0000000000000000000000000000000000000000001100110000011101011101110011000101000001110101100111000111001100111000110000000\n",
      "Uncertainty Mask: 0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000010100000000000000000000000000\n",
      "Overlap Ratio: 0.07142857142857142\n",
      "\n",
      "Example 3:\n",
      "Text: צטניק?\"\n",
      "המשורר דן פגיס אשר נמנע מלהעיד במשפט אייכמן, התעמת בשירו \"עדות\" עם הגדרת אושוויץ כ\"פלנטה אחרת\" וכתב: \"לֹא לֹא / הֵם בְּהֶחְלֵט / הָיוּ בְּנֵי-אָדָם: מַדִּים, מַגָּפַיִם\n",
      "Nikud Mask:       00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000010010000100111100001010110011000110000111100\n",
      "Uncertainty Mask: 01100000000000000001000000000000000000000000000000000000000000000000000000000000001000000000111000000000000000000000000000000000000000000000000000000001000\n",
      "Overlap Ratio: 0.125\n",
      "\n",
      "Example 4:\n",
      "Text: בנוסף, פועלים באי גם מוניות ושרות סמפנים (סירות סיניות ממונעות) בין הרחוב הראשי של אִפּ ליי צ'או לאברדין\n",
      "Nikud Mask:       00000000000000000000000000000000000000000000000000000000000000000000000000000000000011000000000000000000\n",
      "Uncertainty Mask: 00000000000000000000000000000010000101000000000000000000000000000000000000000000000000010001001011110000\n",
      "Overlap Ratio: 0.0\n",
      "\n",
      "Example 5:\n",
      "Text: עם סיום קריירת המשחק שלו בשנת 1959, צ'קואסלי פתח בקריירת ניהול, שבשיאה הגיע אל צמרת מִנהלת הכדורגל בוועד הספורט הממלכתי של גאורגיה הסובייטית - מאוקטובר 1974 עד מרץ 1976 שימש כסגן יו\"ר המִנהלת, ואילו בהמשך עמד בראשה (בין אפריל 1976 לפברואר 1984, ושוב מפברואר 1987 עד נובמבר 1988)\n",
      "Nikud Mask:       00000000000000000000000000000000000000000000000000000000000000000000000000000000000001000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000100000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n",
      "Uncertainty Mask: 00000000000000000000000000000000000001001110000000000000000000000000000000000000000001000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n",
      "Overlap Ratio: 0.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(test)):\n",
    "    print(f\"Example {i+1}:\")\n",
    "    print(\"Text:\", test.iloc[i]['text'])\n",
    "    print(\"Nikud Mask:      \", mask_str(test.iloc[i]['nikud_mask']))\n",
    "    print(\"Uncertainty Mask:\", mask_str(test.iloc[i]['uncertainty_mask']))\n",
    "    print(\"Overlap Ratio:\", test.iloc[i]['uncertainty_overlap_ratio'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "93a0e113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'char': 'ק',\n",
       "  'position': (tensor(5), tensor(6)),\n",
       "  'entropy': 1.7002260453349685,\n",
       "  'margin': 0.10639014840126038,\n",
       "  'max_prob': 0.46183285117149353,\n",
       "  'top_candidates': [('ְּ', 0.46183285117149353),\n",
       "   ('ָּ', 0.35544270277023315),\n",
       "   ('ַּ', 0.14430095255374908),\n",
       "   ('ִּ', 0.025373805314302444),\n",
       "   ('', 0.004338645841926336)]},\n",
       " {'char': 'מ',\n",
       "  'position': (tensor(6), tensor(7)),\n",
       "  'entropy': 1.8923375398731663,\n",
       "  'margin': 0.3622446358203888,\n",
       "  'max_prob': 0.5610603094100952,\n",
       "  'top_candidates': [('ָ', 0.5610603094100952),\n",
       "   ('ְ', 0.19881567358970642),\n",
       "   ('ָּ', 0.1026516854763031),\n",
       "   ('ֵ', 0.0913892388343811),\n",
       "   ('ַ', 0.023114318028092384)]},\n",
       " {'char': 'ל',\n",
       "  'position': (tensor(28), tensor(29)),\n",
       "  'entropy': 1.007569559218598,\n",
       "  'margin': 0.2989606559276581,\n",
       "  'max_prob': 0.6457830667495728,\n",
       "  'top_candidates': [('ַ', 0.6457830667495728),\n",
       "   ('ָ', 0.3468224108219147),\n",
       "   ('ְ', 0.0030318722128868103),\n",
       "   ('', 0.0022456843871623278),\n",
       "   ('ַּ', 0.0006822854629717767)]},\n",
       " {'char': 'ח',\n",
       "  'position': (tensor(37), tensor(38)),\n",
       "  'entropy': 1.5076672169038867,\n",
       "  'margin': 0.5502880960702896,\n",
       "  'max_prob': 0.7078871130943298,\n",
       "  'top_candidates': [('ַ', 0.7078871130943298),\n",
       "   ('ָ', 0.15759901702404022),\n",
       "   ('ֲ', 0.04551473259925842),\n",
       "   ('ִ', 0.03282444179058075),\n",
       "   ('', 0.030110660940408707)]},\n",
       " {'char': 'מ',\n",
       "  'position': (tensor(38), tensor(39)),\n",
       "  'entropy': 1.632634188569759,\n",
       "  'margin': 0.36997297406196594,\n",
       "  'max_prob': 0.6150648593902588,\n",
       "  'top_candidates': [('ְ', 0.6150648593902588),\n",
       "   ('ָ', 0.24509188532829285),\n",
       "   ('ַ', 0.07003997266292572),\n",
       "   ('ֵ', 0.029337119311094284),\n",
       "   ('', 0.016142427921295166)]},\n",
       " {'char': 'ס',\n",
       "  'position': (tensor(39), tensor(40)),\n",
       "  'entropy': 2.130700148660023,\n",
       "  'margin': 0.43633222579956055,\n",
       "  'max_prob': 0.5839293003082275,\n",
       "  'top_candidates': [('ָ', 0.5839293003082275),\n",
       "   ('ַ', 0.147597074508667),\n",
       "   ('ָּ', 0.09151768684387207),\n",
       "   ('ֶ', 0.061459608376026154),\n",
       "   ('', 0.04276083782315254)]},\n",
       " {'char': 'ר',\n",
       "  'position': (tensor(53), tensor(54)),\n",
       "  'entropy': 1.0799215926200814,\n",
       "  'margin': 0.3467923700809479,\n",
       "  'max_prob': 0.6613171100616455,\n",
       "  'top_candidates': [('ְ', 0.6613171100616455),\n",
       "   ('ָ', 0.31452473998069763),\n",
       "   ('ַ', 0.019446339458227158),\n",
       "   ('', 0.0018335009226575494),\n",
       "   ('ֵ', 0.0009912493405863643)]},\n",
       " {'char': 'פ',\n",
       "  'position': (tensor(79), tensor(80)),\n",
       "  'entropy': 1.8382108123014451,\n",
       "  'margin': 0.4528660178184509,\n",
       "  'max_prob': 0.5897095203399658,\n",
       "  'top_candidates': [('ַ', 0.5897095203399658),\n",
       "   ('ָ', 0.1368435025215149),\n",
       "   ('ָּ', 0.11863952875137329),\n",
       "   ('ַּ', 0.10241103172302246),\n",
       "   ('', 0.04259796440601349)]},\n",
       " {'char': 'ט',\n",
       "  'position': (tensor(81), tensor(82)),\n",
       "  'entropy': 1.4407028031105016,\n",
       "  'margin': 0.575647696852684,\n",
       "  'max_prob': 0.7184517979621887,\n",
       "  'top_candidates': [('ְ', 0.7184517979621887),\n",
       "   ('ָ', 0.1428041011095047),\n",
       "   ('', 0.07029750943183899),\n",
       "   ('ַ', 0.024626147001981735),\n",
       "   ('ֶ', 0.016443882137537003)]},\n",
       " {'char': 'מ',\n",
       "  'position': (tensor(82), tensor(83)),\n",
       "  'entropy': 1.2745754535734215,\n",
       "  'margin': 0.6746911481022835,\n",
       "  'max_prob': 0.763735830783844,\n",
       "  'top_candidates': [('ָ', 0.763735830783844),\n",
       "   ('ַ', 0.08904468268156052),\n",
       "   ('ֶ', 0.08135971426963806),\n",
       "   ('', 0.04352687671780586),\n",
       "   ('ָּ', 0.0118925292044878)]},\n",
       " {'char': 'מ',\n",
       "  'position': (tensor(105), tensor(106)),\n",
       "  'entropy': 1.0701131175169303,\n",
       "  'margin': 0.6097042560577393,\n",
       "  'max_prob': 0.7757613062858582,\n",
       "  'top_candidates': [('ַּ', 0.7757613062858582),\n",
       "   ('ַ', 0.1660570502281189),\n",
       "   ('ָּ', 0.039891280233860016),\n",
       "   ('ָ', 0.006005226634442806),\n",
       "   ('', 0.0023201468866318464)]}]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, ambiguous = ht.get_nikud_uncertainty(not_enough_overlap.iloc[0]['text'])\n",
    "ambiguous"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nikud-bert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
